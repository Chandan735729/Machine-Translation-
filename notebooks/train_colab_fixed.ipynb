{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# 🌐 English-Assamese Translation Model Training (Fixed & Optimized)\n",
    "\n",
    "This notebook fine-tunes Meta's NLLB model for English-Assamese translation with **FIXED** issues:\n",
    "- ✅ **Fixed tokenizer deprecation warning**\n",
    "- ✅ **Optimized training parameters for small datasets**\n",
    "- ✅ **Multiple dataset fallback options**\n",
    "- ✅ **Better error handling and GPU memory management**\n",
    "\n",
    "## Setup Instructions:\n",
    "1. **Runtime → Change runtime type → GPU (T4 recommended)**\n",
    "2. **Run all cells in order**\n",
    "3. **Monitor training progress**\n",
    "4. **Download the trained model**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Environment Setup & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages with specific versions for stability\n",
    "!pip install -q torch>=2.0.0 transformers>=4.30.0 datasets>=2.12.0\n",
    "!pip install -q accelerate>=0.20.0 sentencepiece>=0.1.99 protobuf>=3.20.0\n",
    "!pip install -q pandas>=2.0.0 numpy>=1.24.0 tqdm>=4.65.0\n",
    "\n",
    "# Check GPU availability and memory\n",
    "import torch\n",
    "import gc\n",
    "print(f\"🔥 CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"🎮 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"💾 Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"💾 Available Memory: {torch.cuda.memory_reserved(0) / 1e9:.1f} GB\")\n",
    "    # Clear any existing GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"🧹 GPU memory cleared\")\n",
    "else:\n",
    "    print(\"⚠️  No GPU available - training will be slow on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone_repo"
   },
   "source": [
    "## 2. Clone Repository and Setup Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone"
   },
   "outputs": [],
   "source": [
    "# Clone the repository (replace with your actual repo URL)\n",
    "import os\n",
    "repo_url = \"https://github.com/your-username/Machine-Translation-.git\"  # UPDATE THIS\n",
    "\n",
    "if not os.path.exists(\"Machine-Translation-\"):\n",
    "    print(f\"📥 Cloning repository from {repo_url}\")\n",
    "    !git clone $repo_url\n",
    "else:\n",
    "    print(\"📁 Repository already exists\")\n",
    "\n",
    "%cd Machine-Translation-\n",
    "\n",
    "# Verify project structure\n",
    "print(\"\\n📂 Project structure:\")\n",
    "!ls -la\n",
    "\n",
    "# Create necessary directories\n",
    "!mkdir -p data/processed models results\n",
    "print(\"\\n✅ Project setup completed\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
