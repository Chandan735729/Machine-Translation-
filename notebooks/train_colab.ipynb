{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üåê English-Assamese Translation Model Training\n",
    "\n",
    "This notebook fine-tunes Meta's NLLB model for English-Assamese translation using Google Colab's free GPU.\n",
    "\n",
    "## Setup Instructions:\n",
    "1. **Runtime ‚Üí Change runtime type ‚Üí GPU (T4 recommended)**\n",
    "2. **Run all cells in order**\n",
    "3. **Monitor training progress**\n",
    "4. **Download the trained model**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch transformers datasets accelerate sentencepiece\n",
    "!pip install -q pandas numpy tqdm\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone_repo"
   },
   "source": [
    "## 2. Clone Repository and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone"
   },
   "outputs": [],
   "source": [
    "# Clone the repository (replace with your actual repo URL)\n",
    "!git clone https://github.com/your-username/Machine-Translation-.git\n",
    "%cd Machine-Translation-\n",
    "\n",
    "# List files to verify\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_prep"
   },
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_data"
   },
   "outputs": [],
   "source": [
    "# Import and run data preparation\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from data_preparation import DataPreparator\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Initialize data preparator\n",
    "print(\"üîÑ Initializing data preparation...\")\n",
    "preparator = DataPreparator()\n",
    "\n",
    "# Load and prepare dataset\n",
    "print(\"üì• Loading dataset...\")\n",
    "raw_dataset = preparator.load_dataset()\n",
    "\n",
    "print(\"‚öôÔ∏è Processing dataset...\")\n",
    "processed_dataset = preparator.prepare_datasets(raw_dataset)\n",
    "\n",
    "# Save processed data\n",
    "print(\"üíæ Saving processed data...\")\n",
    "preparator.save_processed_data(processed_dataset)\n",
    "\n",
    "# Print statistics\n",
    "stats = preparator.get_data_stats(processed_dataset)\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "# Import training modules\n",
    "from train import TranslationTrainer\n",
    "import os\n",
    "\n",
    "# Initialize trainer\n",
    "print(\"ü§ñ Initializing translation trainer...\")\n",
    "trainer_obj = TranslationTrainer()\n",
    "\n",
    "# Load processed data\n",
    "print(\"üìÇ Loading processed dataset...\")\n",
    "dataset = trainer_obj.load_processed_data()\n",
    "\n",
    "print(f\"\\nüìã Training Configuration:\")\n",
    "print(f\"  Model: facebook/nllb-200-distilled-600M\")\n",
    "print(f\"  Train samples: {len(dataset['train'])}\")\n",
    "print(f\"  Validation samples: {len(dataset.get('validation', []))}\")\n",
    "print(f\"  Device: {trainer_obj.device}\")\n",
    "\n",
    "# Start training\n",
    "print(\"\\nüöÄ Starting model training...\")\n",
    "print(\"This may take 30-60 minutes depending on your GPU.\")\n",
    "\n",
    "trainer, model_path = trainer_obj.train_model(dataset)\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed!\")\n",
    "print(f\"üìÅ Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate"
   },
   "outputs": [],
   "source": [
    "# Evaluate the trained model\n",
    "print(\"üìä Evaluating model performance...\")\n",
    "eval_results = trainer_obj.evaluate_model(trainer, dataset)\n",
    "\n",
    "print(f\"\\nüìà Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_translation"
   },
   "source": [
    "## 6. Test Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test"
   },
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "from translate import EnglishToAssameseTranslator\n",
    "\n",
    "# Initialize translator with trained model\n",
    "print(\"üîÑ Loading trained model for testing...\")\n",
    "translator = EnglishToAssameseTranslator(model_path)\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"Community health workers are the backbone of our medical system.\",\n",
    "    \"Education is the key to development.\",\n",
    "    \"Clean water is essential for good health.\",\n",
    "    \"Hello, how are you?\",\n",
    "    \"Thank you for your help.\"\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ Testing translations:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, sentence in enumerate(test_sentences, 1):\n",
    "    print(f\"\\n{i}. English: {sentence}\")\n",
    "    translation = translator.translate(sentence)\n",
    "    print(f\"   Assamese: {translation}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\n‚úÖ Translation testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 7. Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_model"
   },
   "outputs": [],
   "source": [
    "# Create a zip file of the trained model\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "model_dir = \"models/nllb-finetuned-en-to-asm-final\"\n",
    "\n",
    "if os.path.exists(model_dir):\n",
    "    print(\"üì¶ Creating model archive...\")\n",
    "    \n",
    "    # Create zip file\n",
    "    shutil.make_archive(\"trained_model\", 'zip', model_dir)\n",
    "    \n",
    "    print(\"‚úÖ Model archived as 'trained_model.zip'\")\n",
    "    print(\"üì• Download it from the Files panel on the left\")\n",
    "    \n",
    "    # Show file size\n",
    "    size_mb = os.path.getsize(\"trained_model.zip\") / (1024 * 1024)\n",
    "    print(f\"üìä Archive size: {size_mb:.1f} MB\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Model directory not found. Training may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_to_drive"
   },
   "source": [
    "## 8. Optional: Upload to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drive_upload"
   },
   "outputs": [],
   "source": [
    "# Optional: Mount Google Drive and upload model\n",
    "from google.colab import drive\n",
    "import shutil\n",
    "\n",
    "# Mount Google Drive\n",
    "print(\"üîó Mounting Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy model to Drive\n",
    "drive_path = \"/content/drive/MyDrive/translation_models/\"\n",
    "os.makedirs(drive_path, exist_ok=True)\n",
    "\n",
    "if os.path.exists(\"trained_model.zip\"):\n",
    "    shutil.copy(\"trained_model.zip\", f\"{drive_path}trained_model.zip\")\n",
    "    print(f\"‚úÖ Model uploaded to Google Drive: {drive_path}\")\n",
    "else:\n",
    "    print(\"‚ùå Model archive not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## üéâ Training Complete!\n",
    "\n",
    "### Next Steps:\n",
    "1. **Download** the trained model (`trained_model.zip`)\n",
    "2. **Extract** it to your local project's `models/` directory\n",
    "3. **Update** the model path in your local `translate.py` if needed\n",
    "4. **Test** the model locally using the FastAPI backend\n",
    "\n",
    "### Model Usage:\n",
    "```python\n",
    "from translate import EnglishToAssameseTranslator\n",
    "\n",
    "translator = EnglishToAssameseTranslator(\"models/nllb-finetuned-en-to-asm-final\")\n",
    "result = translator.translate(\"Hello, how are you?\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "### Deployment:\n",
    "- Place the model in your project directory\n",
    "- Run the FastAPI server: `python api/main.py`\n",
    "- Access the web interface at `http://localhost:8000`\n",
    "\n",
    "---\n",
    "**Happy Translating! üåê**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
